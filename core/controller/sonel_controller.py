"""
Controlador principal del sistema Sonel Analysis

Este m√≥dulo encapsula toda la l√≥gica de procesamiento que antes estaba en main.py,
permitiendo su uso tanto desde GUI como desde CLI de forma modular.

Autor: Refactorizado para arquitectura modular
Fecha: 2025
"""

import os
import sys
import time
import logging
import traceback
from pathlib import Path
from typing import Tuple, Dict, Any, Optional

from core.etl.sonel_etl import SonelETL
from config.logger import get_logger
from core.database.connection import DatabaseConnection
from core.extractors.pywin_extractor import SonelExtractorCompleto
from config.settings import get_full_config, validate_configuration, validate_screen_resolution


class SonelController:
    """
    Controlador principal que maneja tanto la extracci√≥n PYWIN como el procesamiento ETL
    de forma modular y reutilizable desde cualquier interfaz (GUI o CLI)
    """

    def __init__(self, config_file: Optional[str] = None):
        """
        Inicializa el controlador
        
        Args:
            config_file: Ruta al archivo de configuraci√≥n (opcional)
        """
        self.config_file = config_file or os.path.join("config", "config.ini")
        self.win_config = get_full_config()
        
        # Configurar logger
        self.logger = get_logger("sonel_controller", f"{__name__}_controller")
        self.logger.setLevel(getattr(logging, self.win_config['LOGGING']['level']))
        
        # Configurar rutas
        self.rutas = self._configurar_rutas()
        
        self.logger.info("üéØ Controlador Sonel inicializado correctamente")

    def _configurar_rutas(self) -> Dict[str, str]:
        """
        Configura las rutas del sistema
        
        Returns:
            dict: Diccionario con las rutas configuradas
        """
        return {
            "input_directory": self.win_config['PATHS']['input_dir'],
            "output_directory": self.win_config['PATHS']['export_dir'], 
            "sonel_exe_path": self.win_config['PATHS']['sonel_exe_path']
        }

    def validate_environment(self) -> bool:
        """
        Valida que el entorno est√© configurado correctamente
        
        Returns:
            bool: True si el entorno es v√°lido
        """
        self.logger.info("üîç Validando entorno de ejecuci√≥n...")
        
        try:
            # Validar configuraci√≥n general
            if not validate_configuration():
                self.logger.error("‚ùå Configuraci√≥n general inv√°lida")
                return False
            
            # Validar resoluci√≥n de pantalla para GUI
            validate_screen_resolution()
            
            # Crear directorio de salida si no existe
            os.makedirs(self.rutas["output_directory"], exist_ok=True)
            
            self.logger.info("‚úÖ Entorno validado correctamente")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error en validaci√≥n de entorno: {e}")
            return False

    def run_pywinauto_extraction(self) -> Tuple[bool, Dict[str, Any]]:
        """
        Ejecuta la extracci√≥n GUI usando pywinauto
        
        Returns:
            tuple: (success: bool, extraction_summary: dict)
        """
        self.logger.info("üöÄ === INICIANDO EXTRACCI√ìN PYWIN ===")
        
        try:
            # Verificar requisitos
            if not self.validate_environment():
                self.logger.error("‚ùå No se pueden cumplir los requisitos del sistema")
                return False, self._get_empty_extraction_summary("Error en validaci√≥n de entorno")
            
            # Crear instancia del extractor
            self.logger.info("üîß Inicializando extractor...")
            extractor = SonelExtractorCompleto(
                input_dir=self.rutas["input_directory"],
                output_dir=self.rutas["output_directory"], 
                ruta_exe=self.rutas["sonel_exe_path"]
            )
            
            # Ejecutar procesamiento completo din√°mico
            self.logger.info("üéØ Iniciando procesamiento completo...")
            resultados = extractor.ejecutar_extraccion_completa_dinamica()
            
            # Validar resultados
            if not self._validar_resultados_extraccion(resultados):
                return False, self._get_empty_extraction_summary("Error en validaci√≥n de resultados")
            
            # Obtener resumen de extracci√≥n del extractor
            extraction_summary = extractor.get_extraction_summary_for_gui()
            
            # Procesar resultados y determinar √©xito
            archivos_exitosos = resultados.get('procesados_exitosos', 0)
            archivos_saltados = resultados.get('saltados', 0)
            archivos_fallidos = resultados.get('procesados_fallidos', 0)
            
            # Determinar √©xito basado en la l√≥gica del negocio
            if archivos_exitosos > 0:
                success = True
                extracted_files = archivos_exitosos
            elif archivos_saltados > 0 and archivos_fallidos == 0:
                success = True
                extracted_files = 0  # Ya procesados previamente
            else:
                success = False
                extracted_files = 0
            
            # Agregar informaci√≥n adicional al resumen para la GUI
            extraction_summary.update({
                'success': success,
                'extracted_files': extracted_files,
                'procesados_exitosos': archivos_exitosos,
                'procesados_fallidos': archivos_fallidos,
                'saltados': archivos_saltados
            })
            
            self.logger.info(f"‚úÖ Extracci√≥n completada - √âxito: {success}, Archivos: {extracted_files}")
            
            return success, extraction_summary
            
        except Exception as e:
            self.logger.error(f"‚ùå Error durante extracci√≥n PYWIN: {e}")
            self.logger.error(traceback.format_exc())
            return False, self._get_empty_extraction_summary(f"Error cr√≠tico: {str(e)}")

    def _get_empty_extraction_summary(self, error_message: str = "") -> Dict[str, Any]:
        """Genera un resumen de extracci√≥n vac√≠o para casos de error"""
        return {
            'processed_files': 0,
            'total_files': 0,
            'warnings': 0,
            'errors': 1 if error_message else 0,
            'csv_files_generated': 0,
            'execution_time': '0:00',
            'total_size': '0 MB',
            'files_detail': [],
            'success': False,
            'extracted_files': 0,
            'procesados_exitosos': 0,
            'procesados_fallidos': 1 if error_message else 0,
            'saltados': 0,
            'error_message': error_message
        }

    def run_etl_processing(self, force_reprocess: bool = False) -> Tuple[bool, Dict[str, Any]]:
        """
        Ejecuta el procesamiento ETL de los archivos CSV
        
        Args:
            force_reprocess: Si True, reprocesa todos los archivos ignorando el registro
            
        Returns:
            tuple: (success: bool, summary_data: dict) - Estado y resumen detallado
        """
        self.logger.info("üöÄ === INICIANDO PROCESAMIENTO ETL ===")
        
        db_connection = None
        etl = None
        
        try:
            # Inicializar conexi√≥n a base de datos
            from config.settings import load_config
            etl_config = load_config(self.config_file)
            
            db_connection = DatabaseConnection(etl_config)
            if not db_connection.connect():
                self.logger.error("‚ùå No se pudo establecer conexi√≥n con la base de datos")
                return False, self._get_error_summary("Error de conexi√≥n BD")
            
            self.logger.info("‚úÖ Conexi√≥n a base de datos establecida")
            
            # Inicializar ETL
            etl = SonelETL(
                config_file=self.config_file,
                db_connection=db_connection
            )
            
            # Directorio donde est√°n los CSV
            csv_directory = self.rutas["output_directory"]
            self.logger.info(f"üìÇ Procesando archivos CSV desde: {csv_directory}")
            
            # Ejecutar procesamiento ETL
            success = etl.run(
                extraction_method='file',
                directory=csv_directory,
                force_reprocess=force_reprocess
            )
            
            # Generar resumen
            if success:
                self.logger.info("‚úÖ Procesamiento ETL completado exitosamente")
                summary_data = etl.get_complete_summary_for_gui()
                self._log_summary(summary_data)
                return True, summary_data
            else:
                self.logger.warning("‚ö†Ô∏è El procesamiento ETL se complet√≥ con advertencias")
                summary_data = etl.get_complete_summary_for_gui()
                self._log_summary(summary_data)
                return True, summary_data
                    
        except Exception as e:
            self.logger.error(f"‚ùå Error durante procesamiento ETL: {e}")
            self.logger.error(traceback.format_exc())
            return False, self._get_error_summary(f"Error ETL: {str(e)}")
            
        finally:
            # Limpieza de recursos
            if etl:
                etl.close()
            if db_connection:
                db_connection.close()
            self.logger.info("üßπ Recursos liberados correctamente")

    def run_complete_workflow(self, force_reprocess: bool = False, 
                             skip_gui: bool = False, skip_etl: bool = False) -> Tuple[bool, Dict[str, Any]]:
        """
        Ejecuta el flujo completo: extracci√≥n GUI + procesamiento ETL
        
        Args:
            force_reprocess: Fuerza el reprocesamiento en ETL
            skip_gui: Omite la extracci√≥n GUI
            skip_etl: Omite el procesamiento ETL
            
        Returns:
            tuple: (success: bool, complete_summary: dict) - Estado y resumen completo
        """
        self.logger.info("üéØ === INICIANDO FLUJO COMPLETO SONEL ===")
        start_time = time.time()
        
        # Validar entorno
        if not self.validate_environment():
            self.logger.error("‚ùå Validaci√≥n de entorno fallida")
            return False, self._get_error_summary("Validaci√≥n de entorno fallida")
        
        gui_success = True
        extraction_summary = {}
    
        # Paso 1: Extracci√≥n GUI (opcional)
        if not skip_gui:
            gui_success, extraction_summary = self.run_pywinauto_extraction()
            if not gui_success:
                self.logger.warning("‚ö†Ô∏è Extracci√≥n PYWIN fall√≥, continuando con ETL...")
        else:
            self.logger.info("‚è≠Ô∏è Extracci√≥n PYWIN omitida por configuraci√≥n")
            extraction_summary = self._get_empty_extraction_summary()
        
        # Log del resumen de extracci√≥n
        self._log_extraction_summary(extraction_summary)

        # Paso 2: Procesamiento ETL (opcional)
        etl_success = True
        db_summary = {}
        
        if not skip_etl:
            etl_success, db_summary = self.run_etl_processing(force_reprocess)
            if not etl_success:
                self.logger.error("‚ùå Procesamiento ETL fall√≥")
        else:
            self.logger.info("‚è≠Ô∏è Procesamiento ETL omitido por configuraci√≥n")
            db_summary = self._get_empty_db_summary()
        
        # Generar resumen final
        end_time = time.time()
        total_time = end_time - start_time
        
        overall_success = (gui_success or skip_gui) and (etl_success or skip_etl)
        
        # Log final
        self._log_workflow_completion(gui_success, extraction_summary.get('extracted_files', 0), 
                                 etl_success, total_time, overall_success)
    
        # Generar resumen completo
        complete_summary = self._build_complete_summary_with_extraction(
            gui_success, extraction_summary, etl_success, db_summary, total_time
        )
        
        return overall_success, complete_summary

    def _build_complete_summary_with_extraction(self, gui_success: bool, extraction_summary: Dict[str, Any], 
                                           etl_success: bool, db_summary: Dict[str, Any], 
                                           total_time: float) -> Dict[str, Any]:
        """Construye el resumen completo del flujo incluyendo detalles de extracci√≥n"""
        # Formatear tiempo
        minutes = int(total_time // 60)
        seconds = int(total_time % 60)
        time_str = f"{minutes}:{seconds:02d}"
        
        # Determinar estado general
        if gui_success and etl_success:
            overall_status = "‚úÖ Completado"
        elif gui_success or etl_success:
            overall_status = "‚ö†Ô∏è Parcial"
        else:
            overall_status = "‚ùå Fallido"
        
        return {
            # Informaci√≥n general
            'overall_status': overall_status,
            'total_files': extraction_summary.get('total_files', 0),
            'total_time': time_str,
            'success_rate': db_summary.get('success_rate', 0),
            'connection_status': db_summary.get('connection_status', 'Desconocido'),
            'gui_success': gui_success,
            'etl_success': etl_success,
            
            # Informaci√≥n de extracci√≥n CSV
            'csv_extracted': extraction_summary.get('csv_files_generated', 0),
            'csv_processed_files': extraction_summary.get('processed_files', 0),
            'csv_warnings': extraction_summary.get('warnings', 0),
            'csv_errors': extraction_summary.get('errors', 0),
            'csv_execution_time': extraction_summary.get('execution_time', '0:00'),
            'csv_total_size': extraction_summary.get('total_size', '0 MB'),
            
            # Informaci√≥n de base de datos
            'db_uploaded': db_summary.get('uploaded_files', 0),
            'total_errors': db_summary.get('failed_uploads', 0),
            'data_processed': db_summary.get('inserted_records', 0),
            'data_size': db_summary.get('data_size', '0 bytes'),
            
            # Res√∫menes detallados
            'extraction_summary': extraction_summary,
            'db_summary': db_summary,
            'files': db_summary.get('files', [])
        }

    def _log_extraction_summary(self, extraction_summary: Dict[str, Any]) -> None:
        """Log del resumen de extracci√≥n desde el controlador"""
        self.logger.info("\n" + "üéØ" * 30)
        self.logger.info("üìä RESUMEN DE EXTRACCI√ìN CSV DESDE CONTROLADOR")
        self.logger.info("üéØ" * 30)
        self.logger.info(f"üìÅ Archivos procesados: {extraction_summary.get('processed_files', 0)} / {extraction_summary.get('total_files', 0)}")
        self.logger.info(f"‚ö†Ô∏è Advertencias: {extraction_summary.get('warnings', 0)}")
        self.logger.info(f"‚ùå Errores: {extraction_summary.get('errors', 0)}")
        self.logger.info(f"üìÑ CSVs generados: {extraction_summary.get('csv_files_generated', 0)}")
        self.logger.info(f"‚è±Ô∏è Tiempo de extracci√≥n: {extraction_summary.get('execution_time', '0:00')}")
        self.logger.info(f"üíæ Tama√±o procesado: {extraction_summary.get('total_size', '0 MB')}")
        
        # Tasa de √©xito
        total_files = extraction_summary.get('total_files', 0)
        csv_generated = extraction_summary.get('csv_files_generated', 0)
        if total_files > 0:
            success_rate = (csv_generated / total_files) * 100
            self.logger.info(f"üìà Tasa de √©xito: {success_rate:.1f}%")
        
        self.logger.info("üéØ" * 30)

    def get_folder_info(self, folder_path: str) -> Dict[str, Any]:
        """
        Obtiene informaci√≥n de una carpeta de archivos PQM
        
        Args:
            folder_path: Ruta de la carpeta
            
        Returns:
            dict: Informaci√≥n de la carpeta
        """
        try:
            if not os.path.exists(folder_path):
                return {"error": "La carpeta no existe", "count": 0, "files": []}
            
            # Extensiones v√°lidas
            valid_extensions = ('.pqm702', '.pqm710', '.pqm711')
            
            # Obtener archivos v√°lidos
            files = [f for f in os.listdir(folder_path) 
                    if f.lower().endswith(valid_extensions)]
            
            return {
                "count": len(files),
                "files": files,
                "path": folder_path,
                "valid_extensions": valid_extensions
            }
            
        except Exception as e:
            self.logger.error(f"Error obteniendo info de carpeta: {e}")
            return {"error": str(e), "count": 0, "files": []}

    # M√©todos auxiliares privados
    def _validar_resultados_extraccion(self, resultados: Any) -> bool:
        """Valida que los resultados de extracci√≥n sean v√°lidos"""
        if resultados is None:
            self.logger.error("‚ùå El extractor devolvi√≥ None - procesamiento fallido")
            return False
        
        if not isinstance(resultados, dict):
            self.logger.error(f"‚ùå El extractor devolvi√≥ tipo inv√°lido: {type(resultados)}")
            return False
        
        # Verificar claves requeridas
        claves_requeridas = ['procesados_exitosos', 'procesados_fallidos', 'saltados', 'csvs_verificados']
        for clave in claves_requeridas:
            if clave not in resultados:
                self.logger.warning(f"‚ö†Ô∏è Clave faltante en resultados: {clave}, usando valor por defecto 0")
                resultados[clave] = 0
        
        if 'detalles' not in resultados:
            resultados['detalles'] = []
        
        return True

    def _procesar_resultados_extraccion(self, resultados: Dict[str, Any]) -> Tuple[bool, int]:
        """Procesa los resultados de extracci√≥n y determina el √©xito"""
        archivos_exitosos = resultados.get('procesados_exitosos', 0)
        archivos_saltados = resultados.get('saltados', 0)
        archivos_fallidos = resultados.get('procesados_fallidos', 0)
        
        self._mostrar_resumen_extraccion(resultados)
        
        # L√≥gica de √©xito
        if archivos_exitosos > 0:
            self.logger.info(f"‚úÖ Extracci√≥n PYWIN exitosa: {archivos_exitosos} archivos procesados")
            return True, archivos_exitosos
        elif archivos_saltados > 0 and archivos_fallidos == 0:
            self.logger.info(f"‚úÖ Extracci√≥n PYWIN exitosa: Todos los archivos ya procesados ({archivos_saltados} saltados)")
            return True, 0
        elif archivos_saltados == 0 and archivos_exitosos == 0 and archivos_fallidos == 0:
            self.logger.info("‚ÑπÔ∏è No se encontraron archivos para procesar")
            return True, 0
        else:
            self.logger.warning(f"‚ö†Ô∏è Extracci√≥n PYWIN completada con {archivos_fallidos} fallos")
            return False, archivos_exitosos

    def _mostrar_resumen_extraccion(self, resultados: Dict[str, Any]) -> None:
        """Muestra el resumen de extracci√≥n"""
        procesados_exitosos = resultados.get('procesados_exitosos', 0)
        procesados_fallidos = resultados.get('procesados_fallidos', 0)
        saltados = resultados.get('saltados', 0)
        csvs_verificados = resultados.get('csvs_verificados', 0)
        
        # Determinar mensaje de estado
        if procesados_exitosos > 0:
            estado_mensaje = "‚úÖ PROCESAMIENTO EXITOSO"
        elif saltados > 0 and procesados_fallidos == 0:
            estado_mensaje = "‚úÖ PROCESAMIENTO COMPLETO - TODOS LOS ARCHIVOS YA PROCESADOS"
        elif procesados_fallidos > 0:
            estado_mensaje = "‚ö†Ô∏è PROCESAMIENTO COMPLETADO CON ERRORES"
        else:
            estado_mensaje = "‚ÑπÔ∏è NO SE ENCONTRARON ARCHIVOS PARA PROCESAR"
        
        self.logger.info(f"\n{'='*50}")
        self.logger.info(estado_mensaje)
        self.logger.info(f"{'='*50}")
        self.logger.info(f"üìä Exitosos:        {procesados_exitosos}")
        self.logger.info(f"üìÑ CSVs verificados: {csvs_verificados}")
        self.logger.info(f"‚ùå Fallidos:        {procesados_fallidos}")
        self.logger.info(f"‚è≠Ô∏è  Saltados:        {saltados}")
        self.logger.info(f"{'='*50}")

    def _log_summary(self, summary: Dict[str, Any]) -> None:
        """Log del resumen ETL"""
        self.logger.info("üìä Resumen del flujo:")
        for k, v in summary.items():
            self.logger.info(f"   ‚Ä¢ {k:15}: {v}")

    def _log_workflow_completion(self, gui_success: bool, extracted_files: int, 
                                etl_success: bool, total_time: float, overall_success: bool) -> None:
        """Log de finalizaci√≥n del workflow"""
        self.logger.info("üèÅ === RESUMEN DEL FLUJO COMPLETO ===")
        self.logger.info(f"‚è±Ô∏è Tiempo total de ejecuci√≥n: {total_time:.2f} segundos")
        
        if gui_success and extracted_files > 0:
            self.logger.info(f"üîÑ Extracci√≥n PYWIN: ‚úÖ Exitosa - {extracted_files} archivos nuevos procesados")
        elif gui_success and extracted_files == 0:
            self.logger.info("üîÑ Extracci√≥n PYWIN: ‚úÖ Exitosa - Todos los archivos ya procesados")
        else:
            self.logger.info("üîÑ Extracci√≥n PYWIN: ‚ùå Fall√≥")
        
        self.logger.info(f"üìä Archivos extra√≠dos: {extracted_files}")
        self.logger.info(f"üíæ Procesamiento ETL: {'‚úÖ Exitoso' if etl_success else '‚ùå Fall√≥'}")
        self.logger.info(f"üéØ Resultado general: {'‚úÖ √âXITO' if overall_success else '‚ùå FALLO'}")

    def _get_error_summary(self, error_message: str) -> Dict[str, Any]:
        """Genera un resumen de error est√°ndar"""
        return {
            'total_files': 0,
            'uploaded_files': 0,
            'failed_uploads': 1,
            'conflicts': 0,
            'inserted_records': 0,
            'success_rate': 0,
            'upload_time': '0:00',
            'updated_indexes': 0,
            'connection_status': 'Error',
            'files': [],
            'error_message': error_message
        }

    def _get_empty_db_summary(self) -> Dict[str, Any]:
        """Genera un resumen vac√≠o para cuando se omite ETL"""
        return {
            'total_files': 0,
            'uploaded_files': 0,
            'failed_uploads': 0,
            'conflicts': 0,
            'inserted_records': 0,
            'success_rate': 0,
            'upload_time': '0:00',
            'updated_indexes': 0,
            'connection_status': 'Omitido',
            'files': []
        }

    def _build_complete_summary(self, gui_success: bool, extracted_files: int, 
                               etl_success: bool, db_summary: Dict[str, Any], 
                               total_time: float) -> Dict[str, Any]:
        """Construye el resumen completo del flujo"""
        # Formatear tiempo
        minutes = int(total_time // 60)
        seconds = int(total_time % 60)
        time_str = f"{minutes}:{seconds:02d}"
        
        # Determinar estado general
        if gui_success and etl_success:
            overall_status = "‚úÖ Completado"
        elif gui_success or etl_success:
            overall_status = "‚ö†Ô∏è Parcial"
        else:
            overall_status = "‚ùå Fallido"
        
        return {
            'overall_status': overall_status,
            'total_files': db_summary.get('total_files', 0),
            'csv_extracted': extracted_files,
            'db_uploaded': db_summary.get('uploaded_files', 0),
            'total_errors': db_summary.get('failed_uploads', 0),
            'total_time': time_str,
            'success_rate': db_summary.get('success_rate', 0),
            'data_processed': db_summary.get('inserted_records', 0),
            'connection_status': db_summary.get('connection_status', 'Desconocido'),
            'gui_success': gui_success,
            'etl_success': etl_success,
            'db_summary': db_summary
        }
    
    